{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interval estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimation framework, reminder\n",
    "\n",
    "The framework we consider is the following. We have $N$ data points modelled as a vector $y \\in \\mathbb{R}^N$. We have a model for the data, that is the data is assumed to have a distribution $ p(y|\\theta)$ for a certain parameter $\\theta$ that we wish to estimate. The function $\\theta \\rightarrow p(y|\\theta)$ is called the likelihood. \n",
    "\n",
    "For instance, we have $N$ data points, independent statistically, each data point is assumed to follow a Gaussian distribution of mean $\\mu$ and variance $\\sigma_k^2$, denoted by $Y_k \\sim G(\\mu, \\sigma_k^2)$. Let us suppose that the $\\sigma_k^2$ are known, so that the only unknown parameter is $\\mu$ (it plays the role of $\\theta$ in the definition of the likelihood). The likelihood of the data point $Y_k$ is then \n",
    "$$p(y_k|\\mu)  = \\frac{1}{\\sqrt{2\\pi} \\sigma_k} \\mathrm{e}^{-\\frac{1}{2\\sigma_k^2} (y_k - \\mu)^2}$$\n",
    "Since all the $Y_k$ are independent, the likelihood of the data $Y$ is the product of the likelihoods of the $Y_k$,\n",
    "$$p(y|\\mu)  = \\prod\\limits_{k=1}^N  p(y_k|\\mu) =\\prod\\limits_{k=1}^N \\frac{1}{\\sqrt{2\\pi} \\sigma_k} \\mathrm{e}^{-\\frac{1}{2\\sigma_k^2} (y_k - \\mu)^2} = \\frac{1}{\\sqrt{2\\pi}^N \\prod\\limits_{k=1}^N \\sigma_k} \\mathrm{e}^{-\\frac{1}{2} \\sum\\limits_{k=1}^N \\frac{(y_k - \\mu)^2}{\\sigma_k^2} } $$\n",
    "\n",
    "Furthermore, we might assume that the parameter itself has a prior distrbution. That is, the probability of $\\theta$ before seeing the data is $p(\\theta)$. In the example above, we could assume that $p(\\mu)$ is a Gaussian distribution of mean $0$ and variance $\\sigma_\\mu$ \n",
    "\n",
    "#### Point estimates, reminder\n",
    "\n",
    "In the previous lesson we have studied the point estimates. In the point estimates view, we have an estimator $\\hat{\\theta}:y \\rightarrow \\hat{\\theta}(y)$ that takes as argument the data $y$ and outputs a value wanted to be close to  $\\theta$. The error bar is then given as the variance or square root mean squared error ($\\sqrt{\\mathrm{MSE}}$) of $\\hat{\\theta}$.\n",
    "\n",
    "Some point estimates ignore the prior distributions, while some take it into account. The most common estimators that do not involve the prior are the maximum likelihood and least square estimates. When the Likelihood of the data is Gaussian and the covariance is known, they are equivalent. In the example above, the maximum likelihood estimate is \n",
    "$$\\hat{\\mu}_{ML} = \\arg \\max_\\mu  p(y|\\mu)  = \\frac{\\sum\\limits_{k=1}^N \\frac{y_k}{\\sigma_k^2} }{\\sum\\limits_{k=1}^N \\frac{1}{\\sigma_k^2}} $$\n",
    "\n",
    "If we assume a prior on $\\mu$, $p(\\mu)$, the common estimators are the mean, median and a posteriori, that are\n",
    "$$ \\hat{\\theta}_{\\mathrm{mean}} = \\int_{-\\infty}^\\infty \\mu p(\\mu|y) \\mathrm{d} \\mu  =\\int_{-\\infty}^\\infty \\mu \\frac{p(y|\\mu) p(\\mu)   }{p(y)}  \\mathrm{d} \\mu  $$\n",
    "$$ \\hat{\\theta}_{\\mathrm{median}} = \\mathrm{median}(p(\\mu|y)) $$\n",
    "$$ \\hat{\\theta}_{\\mathrm{mode}} = \\mathrm{mode}(p(\\mu|y)) $$\n",
    "where the mode is the argument that maximizes the a function, $\\mathrm{mode}(p(\\mu|y)) = \\arg \\max_\\mu p(\\mu|y)$.\n",
    "\n",
    "In the example above, $$\\hat{\\theta}_{\\mathrm{mean}} = \\hat{\\theta}_{\\mathrm{median}} = \\hat{\\theta}_{\\mathrm{mode}} = \\frac{\\sum\\limits_{k=1}^N \\frac{y_k}{\\sigma_k^2} }{\\frac{1}{\\sigma_\\mu^2} +\\sum\\limits_{k=1}^N \\frac{1}{\\sigma_k^2}} $$.\n",
    "\n",
    "If the model is correct, the posterior mean and median have respectively minimal mean squared error and mean absolute error. \n",
    "\n",
    "#### Interval estimates\n",
    "\n",
    "In this spreadsheet, we change the viewpoint of the estimation. Instead of aiming at finding an estimator that is optimal in a certain sense, we consider the question: how likely is it that the true value of the parameters lie in a certain interval ? \n",
    "\n",
    "''Likely'' is a loose term that needs clarifications. There are two main ways of constructing interval estimates: the confidence intervals and the credible intervals, which have different properties.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confidence interval\n",
    "\n",
    "A confidence interval is constructed in the following way. Given a likelihood $p(y|\\theta)$ and data $y$, a confidence interval is constructed by choosing a probability $\\alpha$, and two functions of the data $l_\\alpha(y)$ and $u_\\alpha(y)$ such that \n",
    "$$ \\mathrm{Pr}\\left\\{  \\theta \\in [l_\\alpha(y),   u_\\alpha(y) ] \\;  | \\;Â \\theta \\right\\} = \\alpha $$\n",
    "\n",
    "We first consider an example where we construct a confidence interval for the weighted mean of independent Gaussian variables. \n",
    "$$\\hat{\\mu}_{ML} = \\arg \\max_\\mu  p(y|\\mu)  = \\frac{\\sum\\limits_{k=1}^N \\frac{y_k}{\\sigma_k^2} }{\\sum\\limits_{k=1}^N \\frac{1}{\\sigma_k^2}} $$\n",
    "\n",
    "$\\hat{\\mu}_{ML}$ has a Gaussian distribution of variance $\\sigma_\\hat{\\mu}^2 = \\frac{1}{\\sum\\limits_{k=1}^N \\frac{1}{\\sigma_k^2}}$. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "import scipy.special as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The true value of the parameter is in the interval in 99.724 % of the trials\n"
     ]
    }
   ],
   "source": [
    "# Number of simulations\n",
    "Nsim = 100000\n",
    "N = 10 # Number of data points \n",
    "mean_error = 1 #Mean value of the error bars\n",
    "mu = 1\n",
    "#alpha = 4\n",
    "errors_sigma = mean_error*np.random.chisquare(4,size=N)/4 #Generage values of the error bars\n",
    "k = 3\n",
    "conditions = np.ones(Nsim, dtype=bool)\n",
    "\n",
    "for i in range(Nsim):\n",
    "    \n",
    "    y = mu + np.random.randn(N)*errors_sigma\n",
    "    \n",
    "    mu_estim = np.sum(y/errors_sigma**2) / np.sum(1/errors_sigma**2)\n",
    "    sigma_estim = 1/ np.sqrt(np.sum(1/errors_sigma**2))\n",
    "    \n",
    "    u = mu_estim  + k*sigma_estim\n",
    "    l = mu_estim  - k*sigma_estim\n",
    "    condition = (mu <= u) * (mu >= l)\n",
    "    \n",
    "    conditions[i] = condition \n",
    "    \n",
    "print('The true value of the parameter is in the interval in', np.sum(conditions) /Nsim*100, '% of the trials')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "Compute analytically the probability that the true parameter is in the confidence interval if $l = \\hat{\\mu} - k \\sigma_\\hat{\\mu}$ and $u = \\hat{\\mu} + k \\sigma_\\hat{\\mu}$ for $k = 1, 2, 3$. \n",
    "\n",
    "Does the value of the confidence interval depend on the number of data points ? \n",
    "\n",
    "Compute the centered confidence interval that gives an inclusion probability  $ \\alpha = 50\\%$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that the distribution of data point is Gaussian with mean $\\mu$ and error $\\sigma$, we know that, $\\alpha$ can be calculated using the following definition,\n",
    "\n",
    "$$\\alpha = \\int_{\\mu-k\\sigma}^{\\mu + k\\sigma} \\frac{1}{\\sqrt{2\\pi} \\sigma} e^{-\\frac{(y-\\mu)^2}{2\\sigma^2}} dy$$\n",
    "\n",
    "Making a change of variables, $\\left(\\frac{y-\\mu}{\\sigma}\\right)^2 = u^2$, we can write above equation as,\n",
    "\n",
    "\\begin{equation*}\n",
    "    \\begin{split}\n",
    "        \\alpha &= \\frac{1}{\\sqrt{2\\pi}\\sigma} \\int_{-k}^{k} e^{-\\frac{1}{2}u^2} \\sigma du \\\\\n",
    "        &= \\sqrt{\\frac{2}{\\pi}} \\int_{0}^{k} e^{-\\frac{1}{2}u^2} du\n",
    "    \\end{split}\n",
    "\\end{equation*}\n",
    "\n",
    "In the last line we used the fact that the integral is the even function around the limit. To solve this integration we can make another change of variable $\\frac{u^2}{2} = x$,\n",
    "\n",
    "\\begin{equation*}\n",
    "    \\begin{split}\n",
    "        \\alpha &= \\sqrt{\\frac{2}{\\pi}} \\int_{0}^{k^2/2} e^{-x} \\frac{1}{\\sqrt{2x}} dx \\\\\n",
    "        &= \\frac{1}{\\sqrt{\\pi}} \\int_0^{k^2/2} x^{-1/2} e^{-x} dx \\\\\n",
    "        &= \\frac{1}{\\sqrt{\\pi}} \\left[-\\sqrt{\\pi} (1 - erf(\\sqrt{x}) \\right]^{k^2/2}_0\n",
    "    \\end{split}\n",
    "\\end{equation*}\n",
    "\n",
    "In the last line we used the integral tables to find the value of given integration. Solving last equation one would get that,\n",
    "\n",
    "$$\\alpha = erf\\left(\\frac{k}{\\sqrt{2}}\\right)$$\n",
    "\n",
    "We can check this formula using scipy as follows,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k=1, the probability that the true value would be in interval is  0.6826894921370859\n",
      "For k=2, the probability that the true value would be in interval is  0.9544997361036416\n",
      "For k=3, the probability that the true value would be in interval is  0.9973002039367398\n"
     ]
    }
   ],
   "source": [
    "k1 = np.array([1,2,3])\n",
    "alpha = sp.erf(k1/np.sqrt(2))\n",
    "\n",
    "print('For k=1, the probability that the true value would be in interval is ', alpha[0])\n",
    "print('For k=2, the probability that the true value would be in interval is ', alpha[1])\n",
    "print('For k=3, the probability that the true value would be in interval is ', alpha[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This probability would not depend on the number of data points. (In the last calculation, we didn't use number of data points anywhere, we just used the PDF of the data).\n",
    "\n",
    "Now, we want to calculate the centered confidence interval that gives the inclusion probability $\\alpha=0.5$. That means we want to compute $k$ for given alpha which can be done using the inverse error function.\n",
    "\n",
    "$$k = \\sqrt{2} \\cdot erf^{-1}(\\alpha)$$\n",
    "\n",
    "We can calculate this using the scipy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The confidence interval that gives the inclusion probability of 50% would be at about 0.67-sigma from the center\n"
     ]
    }
   ],
   "source": [
    "alpha1 = 0.5\n",
    "kk = np.sqrt(2)*sp.erfinv(alpha1)\n",
    "print('The confidence interval that gives the inclusion probability of 50% would be at about ' \n",
    "      + str(np.around(kk,2)) + \n",
    "      '-sigma from the center')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "We now consider another example. Suppose we observe\n",
    "$$Y = \\theta + \\epsilon$$ where $\\epsilon$ follows an exponential distribution\n",
    "$f(\\epsilon) = \\frac{1}{\\lambda} \\exp(-\\frac{\\epsilon}{\\lambda})$ and $\\theta$ is the parameter to estimate.\n",
    "\n",
    "Given the data $y$, construct confidence intervals for  68.27, 95.45 and 99.73 $\\%$ for $\\theta$ of the form $[y - x_\\alpha ,y]$. In other words, find $x_\\alpha$ such that $\\theta \\in [y - x_\\alpha ,y]$ with a probability $\\alpha$.\n",
    "\n",
    "Check your calculations with a simulation as above. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The likelihood function for the given exponential distribution would be,\n",
    "\n",
    "$$p(y|\\theta) = \\frac{1}{\\lambda}\\exp{\\left(-\\sum_k \\frac{y_k}{\\lambda}\\right)}$$\n",
    "\n",
    "We can calculate the Maximum Likelihood estimate of $\\hat{\\lambda}$ as follows,\n",
    "\n",
    "\\begin{equation}\n",
    "    \\begin{split}\n",
    "        \\log p(y|\\theta) &= - \\log \\lambda - \\sum_k \\frac{y_k}{\\lambda} \\\\\n",
    "        \\Rightarrow \\frac{d \\log p(y|\\theta)}{d\\lambda} &= -\\frac{1}{\\lambda} + \\sum_k \\frac{y_k}{\\lambda^2} \\\\\n",
    "        \\Rightarrow 0 &= -1 + \\sum_k \\frac{y_k}{\\lambda} \\\\\n",
    "        \\Rightarrow \\hat{\\lambda} &= \\sum_k y_k\n",
    "    \\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "Now, we want to find confidence interval for this distribution. We can do so as we did in the previous case. Let, $\\alpha$ be probability with which true value of $\\lambda$ lies in the given interval $(0,k)$. Then,\n",
    "\n",
    "\\begin{equation}\n",
    "    \\begin{split}\n",
    "        \\alpha &= \\int_0^k \\frac{1}{\\lambda} e^{-x/\\lambda} dx \\\\\n",
    "        &= \\frac{1}{\\lambda} \\left( \\frac{e^{-x/\\lambda}}{-1/\\lambda} \\right)_0^k \\\\\n",
    "        &= 1 - e^{-k/\\lambda}\n",
    "    \\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "Here, $\\lambda$ would be the ML estimate of the parameter. Using above formula, we can find the interval $(0,k)$ for which the $\\hat{\\lambda}$ would be in the interval would be $\\alpha$.\n",
    "\n",
    "$$k = \\lambda \\ln{(1-\\alpha)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The true value of the parameter is in the interval in 0.0 % of the trials\n"
     ]
    }
   ],
   "source": [
    "# Number of simulations\n",
    "Nsim = 100000\n",
    "N = 10 # Number of data points \n",
    "\n",
    "mu = 2\n",
    "alpha = 0.95\n",
    "\n",
    "conditions1 = np.ones(Nsim, dtype=bool)\n",
    "\n",
    "for i in range(Nsim):\n",
    "    \n",
    "    y = np.random.exponential(mu,N)\n",
    "    \n",
    "    mu_estim = np.sum(y)\n",
    "    \n",
    "    l = 0\n",
    "    u = mu_estim*np.log(1-alpha)\n",
    "    condition = (mu <= u) * (mu >= l)\n",
    "    \n",
    "    conditions1[i] = condition \n",
    "    \n",
    "print('The true value of the parameter is in the interval in', np.sum(conditions1) /Nsim*100, '% of the trials')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "We now consider another example. Suppose we observe\n",
    "$$Y = \\theta + \\epsilon$$ where $\\epsilon$ follows a gamma distribution of parameters $\\alpha, \\beta$.\n",
    "\n",
    "Given the data $y$, construct confidence intervals for  68.27, 95.45 and 99.73 $\\%$ for $\\theta$ of the form $[y - x_\\alpha ,y]$. In other words, find $x_\\alpha$ such that $\\mu \\in [y - x_\\alpha ,y]$ with a probability $\\alpha$.\n",
    "\n",
    "Check your calculations with a simulation as above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
