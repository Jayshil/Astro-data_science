{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interval estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimation framework, reminder\n",
    "\n",
    "The framework we consider is the following. We have $N$ data points modelled as a vector $y \\in \\mathbb{R}^N$. We have a model for the data, that is the data is assumed to have a distribution $ p(y|\\theta)$ for a certain parameter $\\theta$ that we wish to estimate. The function $\\theta \\rightarrow p(y|\\theta)$ is called the likelihood. \n",
    "\n",
    "For instance, we have $N$ data points, independent statistically, each data point is assumed to follow a Gaussian distribution of mean $\\mu$ and variance $\\sigma_k^2$, denoted by $Y_k \\sim G(\\mu, \\sigma_k^2)$. Let us suppose that the $\\sigma_k^2$ are known, so that the only unknown parameter is $\\mu$ (it plays the role of $\\theta$ in the definition of the likelihood). The likelihood of the data point $Y_k$ is then \n",
    "$$p(y_k|\\mu)  = \\frac{1}{\\sqrt{2\\pi} \\sigma_k} \\mathrm{e}^{-\\frac{1}{2\\sigma_k^2} (y_k - \\mu)^2}$$\n",
    "Since all the $Y_k$ are independent, the likelihood of the data $Y$ is the product of the likelihoods of the $Y_k$,\n",
    "$$p(y|\\mu)  = \\prod\\limits_{k=1}^N  p(y_k|\\mu) =\\prod\\limits_{k=1}^N \\frac{1}{\\sqrt{2\\pi} \\sigma_k} \\mathrm{e}^{-\\frac{1}{2\\sigma_k^2} (y_k - \\mu)^2} = \\frac{1}{\\sqrt{2\\pi}^N \\prod\\limits_{k=1}^N \\sigma_k} \\mathrm{e}^{-\\frac{1}{2} \\sum\\limits_{k=1}^N \\frac{(y_k - \\mu)^2}{\\sigma_k^2} } $$\n",
    "\n",
    "Furthermore, we might assume that the parameter itself has a prior distrbution. That is, the probability of $\\theta$ before seeing the data is $p(\\theta)$. In the example above, we could assume that $p(\\mu)$ is a Gaussian distribution of mean $0$ and variance $\\sigma_\\mu$ \n",
    "\n",
    "#### Point estimates, reminder\n",
    "\n",
    "In the previous lesson we have studied the point estimates. In the point estimates view, we have an estimator $\\hat{\\theta}:y \\rightarrow \\hat{\\theta}(y)$ that takes as argument the data $y$ and outputs a value wanted to be close to  $\\theta$. The error bar is then given as the variance or square root mean squared error ($\\sqrt{\\mathrm{MSE}}$) of $\\hat{\\theta}$.\n",
    "\n",
    "Some point estimates ignore the prior distributions, while some take it into account. The most common estimators that do not involve the prior are the maximum likelihood and least square estimates. When the Likelihood of the data is Gaussian and the covariance is known, they are equivalent. In the example above, the maximum likelihood estimate is \n",
    "$$\\hat{\\mu}_{ML} = \\arg \\max_\\mu  p(y|\\mu)  = \\frac{\\sum\\limits_{k=1}^N \\frac{y_k}{\\sigma_k^2} }{\\sum\\limits_{k=1}^N \\frac{1}{\\sigma_k^2}} $$\n",
    "\n",
    "If we assume a prior on $\\mu$, $p(\\mu)$, the common estimators are the mean, median and a posteriori, that are\n",
    "$$ \\hat{\\theta}_{\\mathrm{mean}} = \\int_{-\\infty}^\\infty \\mu p(\\mu|y) \\mathrm{d} \\mu  =\\int_{-\\infty}^\\infty \\mu \\frac{p(y|\\mu) p(\\mu)   }{p(y)}  \\mathrm{d} \\mu  $$\n",
    "$$ \\hat{\\theta}_{\\mathrm{median}} = \\mathrm{median}(p(\\mu|y)) $$\n",
    "$$ \\hat{\\theta}_{\\mathrm{mode}} = \\mathrm{mode}(p(\\mu|y)) $$\n",
    "where the mode is the argument that maximizes the a function, $\\mathrm{mode}(p(\\mu|y)) = \\arg \\max_\\mu p(\\mu|y)$.\n",
    "\n",
    "In the example above, $$\\hat{\\theta}_{\\mathrm{mean}} = \\hat{\\theta}_{\\mathrm{median}} = \\hat{\\theta}_{\\mathrm{mode}} = \\frac{\\sum\\limits_{k=1}^N \\frac{y_k}{\\sigma_k^2} }{\\frac{1}{\\sigma_\\mu^2} +\\sum\\limits_{k=1}^N \\frac{1}{\\sigma_k^2}} $$.\n",
    "\n",
    "If the model is correct, the posterior mean and median have respectively minimal mean squared error and mean absolute error. \n",
    "\n",
    "#### Interval estimates\n",
    "\n",
    "In this spreadsheet, we change the viewpoint of the estimation. Instead of aiming at finding an estimator that is optimal in a certain sense, we consider the question: how likely is it that the true value of the parameters lie in a certain interval ? \n",
    "\n",
    "''Likely'' is a loose term that needs clarifications. There are two main ways of constructing interval estimates: the confidence intervals and the credible intervals, which have different properties.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confidence interval\n",
    "\n",
    "A confidence interval is constructed in the following way. Given a likelihood $p(y|\\theta)$ and data $y$, a confidence interval is constructed by choosing a probability $\\alpha$, and two functions of the data $l_\\alpha(y)$ and $u_\\alpha(y)$ such that \n",
    "$$ \\mathrm{Pr}\\left\\{  \\theta \\in [l_\\alpha(y),   u_\\alpha(y) ] \\;  | \\;Â \\theta \\right\\} = \\alpha $$\n",
    "\n",
    "We first consider an example where we construct a confidence interval for the weighted mean of independent Gaussian variables. \n",
    "$$\\hat{\\mu}_{ML} = \\arg \\max_\\mu  p(y|\\mu)  = \\frac{\\sum\\limits_{k=1}^N \\frac{y_k}{\\sigma_k^2} }{\\sum\\limits_{k=1}^N \\frac{1}{\\sigma_k^2}} $$\n",
    "\n",
    "$\\hat{\\mu}_{ML}$ has a Gaussian distribution of variance $\\sigma_\\hat{\\mu}^2 = \\frac{1}{\\sum\\limits_{k=1}^N \\frac{1}{\\sigma_k^2}}$. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The true value of the parameter is in the confidence interval in 68.581 % of the trials\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# Number of simulations\n",
    "Nsim = 100000\n",
    "N = 5 # Number of data points \n",
    "mean_error = 20 #Mean value of the error bars\n",
    "mu = 1\n",
    "alpha = 4\n",
    "errors_sigma = mean_error*np.random.chisquare(4,size=N)/4 #Generage values of the error bars\n",
    "k = 1\n",
    "conditions = np.ones(Nsim, dtype=bool)\n",
    "\n",
    "for i in range(Nsim):\n",
    "    \n",
    "    y = mu + np.random.randn(N)*errors_sigma\n",
    "    \n",
    "    mu_estim = np.sum(y/errors_sigma**2) / np.sum(1/errors_sigma**2)\n",
    "    sigma_estim = 1/ np.sqrt(np.sum(1/errors_sigma**2))\n",
    "    \n",
    "    u = mu_estim  + k*sigma_estim\n",
    "    l = mu_estim  - k*sigma_estim\n",
    "    condition = (mu <= u) * (mu >= l)\n",
    "    \n",
    "    conditions[i] = condition \n",
    "    \n",
    "print('The true value of the parameter is in the confidence interval in', np.sum(conditions) /Nsim*100, '% of the trials')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "Compute analytically the probability that the true parameter is in the confidence interval if $l = \\hat{\\mu} - k \\sigma_\\hat{\\mu}$ and $u = \\hat{\\mu} + k \\sigma_\\hat{\\mu}$ for $k = 1, 2, 3$. \n",
    "\n",
    "\n",
    "<font color='purple'> \n",
    "The event $$ \\hat{\\mu} - k \\sigma \\leqslant \\mu \\leqslant \\hat{\\mu} - k \\sigma $$ is the same as\n",
    "    $$ \\mu - k \\sigma \\leqslant \\hat{\\mu} \\leqslant \\mu - k \\sigma $$\n",
    "    \n",
    "which has a probability $F(\\mu + k \\sigma) -  F(\\mu - k \\sigma)$ to happen, where $F$ is the cumulative distribution function (CDF) of $\\hat{\\mu} $. The CDF of a Gaussian of mean $\\mu$ and variance $\\sigma^2$ is \n",
    "    $$F(x) = \\frac{1}{2} \\left( 1 + erf\\left( \\frac{x-\\mu}{\\sqrt{2}\\sigma}\\right)  \\right) $$\n",
    "Therefore \n",
    "   $$F(\\mu + k \\sigma) -  F(\\mu - k \\sigma) =\\frac{1}{2} \\left( erf\\left( \\frac{k  }{\\sqrt{2}}\\right)  -erf\\left( \\frac{-k  }{\\sqrt{2}}\\right)   \\right)$$ where $erf$ is the error function. Since this function is odd, the probability of interest is \n",
    "    $$F(\\mu + k \\sigma) -  F(\\mu - k \\sigma) = erf\\left( \\frac{k  }{\\sqrt{2}}\\right)$$   \n",
    "    \n",
    "For $k=1,2,3$ we find a probability 0.6827, 0.9545, 0.9973$.\n",
    "\n",
    "<font color='black'> \n",
    "Does the value of the confidence interval depend on the number of data points ? \n",
    "\n",
    "<font color='purple'> \n",
    "It does not, it depends only onn $k$.\n",
    "<font color='black'>    \n",
    "    \n",
    "\n",
    "Compute the centered confidence interval that gives an inclusion probability  $ \\alpha = 50\\%$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The confidence interval hatmu - 0.6744897501960818*sigma_mu, hatmu + 0.6744897501960818*sigma_mu is centered and such that the inclusion probability is 50%\n"
     ]
    }
   ],
   "source": [
    "from scipy.special import erf\n",
    "from scipy.special import erfinv\n",
    "\n",
    "# We search for k such that erf(k/sqrt(2))=0.5<. That is\n",
    "k = erfinv(0.5) * np.sqrt(2)\n",
    "\n",
    "print('The confidence interval hatmu - {}*sigma_mu, hatmu + {}*sigma_mu is centered and such that the inclusion probability is 50%'.format(k,k))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us check this on a simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The true value of the parameter is in the confidence interval in 49.99 % of the trials\n"
     ]
    }
   ],
   "source": [
    "# Number of simulations\n",
    "Nsim = 10000\n",
    "N = 5 # Number of data points \n",
    "mean_error = 20 #Mean value of the error bars\n",
    "mu = 1\n",
    "alpha = 4\n",
    "errors_sigma = mean_error*np.random.chisquare(4,size=N)/4 #Generage values of the error bars\n",
    "k = 0.674489\n",
    "conditions = np.ones(Nsim, dtype=bool)\n",
    "\n",
    "for i in range(Nsim):\n",
    "    \n",
    "    y = mu + np.random.randn(N)*errors_sigma\n",
    "    \n",
    "    mu_estim = np.sum(y/errors_sigma**2) / np.sum(1/errors_sigma**2)\n",
    "    sigma_estim = 1/ np.sqrt(np.sum(1/errors_sigma**2))\n",
    "    \n",
    "    u = mu_estim  + k*sigma_estim\n",
    "    l = mu_estim  - k*sigma_estim\n",
    "    condition = (mu <= u) * (mu >= l)\n",
    "    \n",
    "    conditions[i] = condition \n",
    "    \n",
    "print('The true value of the parameter is in the confidence interval in', np.sum(conditions) /Nsim*100, '% of the trials')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "We now consider another example. Suppose we observe\n",
    "$$Y = \\theta + \\epsilon$$ where $\\epsilon$ follows an exponential distribution\n",
    "$f(\\epsilon) = \\frac{1}{\\lambda} \\exp(-\\frac{\\epsilon}{\\lambda})$ and $\\theta$ is the parameter to estimate.\n",
    "\n",
    "Given the data $y$, construct confidence intervals for  68.27, 95.45 and 99.73 $\\%$ for $\\theta$ of the form $[y - x_\\alpha ,y]$. In other words, find $x_\\alpha$ such that $\\theta \\in [y - x_\\alpha ,y]$ with a probability $\\alpha$.\n",
    "\n",
    "Check your calculations with a simulation as above. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='purple'> \n",
    "    \n",
    "Since $\\epsilon$  >0,  $\\theta$ is in the interval $[y-x_a, y]$ if and only if $\\epsilon$ < $x_a$. \n",
    "Now, what is the probability that  $\\epsilon$ < $x_a$ if epsilon follows an exponential law? It is given by $F(x_a)$ where $F$ is the CDF of an exponential distribution, which is, with the connvention taken above, $F(x) = 1 - \\mathrm{e}^{-\\frac{x}{\\lambda}}$.  Now we search $x_a$ such that $F(x_a^p) = p$ for $p=0.6827, 0.9545$ and $0.9973$, that is $x_a^p = -\\lambda \\ln(1-p)$.\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "We now consider another example. Suppose we observe\n",
    "$$Y = \\theta + \\epsilon$$ where $\\epsilon$ follows a gamma distribution of parameters $\\alpha, \\beta$.\n",
    "\n",
    "Given the data $y$, construct confidence intervals for  68.27, 95.45 and 99.73 $\\%$ for $\\theta$ of the form $[y - x_\\alpha ,y]$. In other words, find $x_\\alpha$ such that $\\mu \\in [y - x_\\alpha ,y]$ with a probability $\\alpha$.\n",
    "\n",
    "Check your calculations with a simulation as above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='purple'> \n",
    "    \n",
    "Same reasonning, since $\\epsilon$  >0,  $\\theta$ is in the interval $[y-x_a, y]$ if and only if $\\epsilon$ < $x_a$. \n",
    "Now, what is the probability that  $\\epsilon$ < $x_a$ if epsilon follows a gamma law? It is given by $F(x_a)$ where $F$ is the CDF of a gamma distribution. In that case, there is no explicit expression of this CDF, which can be obtained for instance with scipy.\n",
    "    \n",
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.gamma.html\n",
    "    \n",
    "The gamma distribution CDF is $F(x) = \\frac{1}{\\Gamma(\\alpha)} \\gamma(\\alpha, \\beta  x)$. To get $F(x) = p$, we proceed as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.57395379 1.54502148 2.95725175]\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import gamma\n",
    "alpha= 1\n",
    "beta = 2\n",
    "\n",
    "#We first find beta*x\n",
    "p = [0.6827, 0.9545 , 0.9973  ]\n",
    "betax_a = gamma.ppf(p, alpha)\n",
    "x_a = betax_a/beta\n",
    "print(x_a)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
